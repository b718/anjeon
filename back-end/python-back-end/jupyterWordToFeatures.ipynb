{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hashlib import sha1\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import sklearn \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "\n",
    "from stop_words import get_stop_words \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline, make_pipeline                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Cyberbullying Tweets csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = pd.read_csv(\"data/cyberbullying_tweets.csv\")\n",
    "tweets_df.head()\n",
    "stop_words_set = set(get_stop_words('en'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cyberbullying_type\n",
       "religion               7998\n",
       "age                    7992\n",
       "gender                 7973\n",
       "ethnicity              7961\n",
       "not_cyberbullying      7945\n",
       "other_cyberbullying    7823\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df[\"cyberbullying_type\"].value_counts()\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Modify Label if the value is 'not_cyberbullying' then 0, otherwise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cyberbullying_type\n",
       "1    39747\n",
       "0     7945\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df[\"cyberbullying_type\"] = tweets_df[\"cyberbullying_type\"].apply(lambda x: 0 if x == \"not_cyberbullying\" else 1)\n",
    "tweets_df[\"cyberbullying_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Each `tweet_text` Filtering (Also, Read **Further Notice**)\n",
    "<hr>\n",
    "\n",
    "`tweet_text` contains emoji or any other languages. To make model easily, we are going to stick to have only English.\n",
    "\n",
    "[**Further Notice**] As we know, if we remove the any emoji or any other languages, we might lose useful information. Then, we might need to change this process in the future.\n",
    "\n",
    "We also want to make all the text lowercase, remove stop words, and remove all links!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kids love mohamad bin zayed city'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df[\"tweet_text\"] = tweets_df[\"tweet_text\"].apply(lambda x: re.sub(r'http\\S+', '', x))\n",
    "tweets_df[\"tweet_text\"] = tweets_df[\"tweet_text\"].apply(lambda x: re.sub(r'[^\\x00-\\x7F]+', '', x))\n",
    "tweets_df[\"tweet_text\"] = tweets_df[\"tweet_text\"].apply(lambda x: re.sub(r'[^a-zA-Z0-9\\s]+', '', x))\n",
    "tweets_df[\"tweet_text\"] = tweets_df[\"tweet_text\"].apply(lambda x: x.lower())\n",
    "tweets_df[\"tweet_text\"] = tweets_df[\"tweet_text\"].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words_set]))\n",
    "\n",
    "#Check this below\n",
    "tweets_df[\"tweet_text\"][21]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tweets_df[\"tweet_text\"]\n",
    "y = tweets_df[\"cyberbullying_type\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.8, random_state=123)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8585647712993836"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Create a vectorizer object with stop_words = \"english\"\n",
    "countvec = CountVectorizer(stop_words=\"english\")\n",
    "\n",
    "# 3. Create a logisticRegression object\n",
    "lr = LogisticRegression(max_iter=1000, random_state=123)\n",
    "\n",
    "# 4. Make a pipeline object\n",
    "pipe = make_pipeline(countvec, lr)\n",
    "\n",
    "# 5. Store the mean values of cross-validation scores\n",
    "cv_score = cross_val_score(pipe, X_train, y_train).mean()\n",
    "cv_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.860557100124335"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Create a vectorizer object with stop_words = \"english\"\n",
    "countvec = CountVectorizer(stop_words=\"english\")\n",
    "\n",
    "# 3. Create a SVM RBF object\n",
    "svm = SVC(kernel=\"rbf\", C=10, gamma=0.1)\n",
    "\n",
    "# 4. Make a pipeline object\n",
    "pipe = make_pipeline(countvec, svm)\n",
    "\n",
    "# 5. Store the mean values of cross-validation scores\n",
    "cv_score = cross_val_score(pipe, X_train, y_train).mean()\n",
    "cv_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8587740301372303"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Create a vectorizer object with stop_words = \"english\"\n",
    "countvec = CountVectorizer(stop_words=\"english\")\n",
    "\n",
    "# 3. Create a RandomForest object\n",
    "rf = RandomForestClassifier(n_jobs=-1, random_state=123)\n",
    "\n",
    "# 4. Make a pipeline object\n",
    "pipe = make_pipeline(countvec, rf)\n",
    "\n",
    "# 5. Store the mean values of cross-validation scores\n",
    "cv_score = cross_val_score(pipe, X_train, y_train).mean()\n",
    "cv_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
